python api to expose s3 files for searching for date criteria
ChatGPT said:

You can create a simple Python API using FastAPI that allows users to search for files in an Amazon S3 bucket based on date criteria. The API will:

    List files in an S3 bucket
    Filter files by creation or last-modified date
    Return matching file details

Steps to Implement:

    Set up FastAPI to create the API
    Use Boto3 to interact with S3
    Filter files based on date criteria

Install Required Libraries

pip install fastapi uvicorn boto3

FastAPI Code

from fastapi import FastAPI, Query
import boto3
from datetime import datetime
from typing import List

# Initialize FastAPI
app = FastAPI()

# AWS S3 Client
s3_client = boto3.client("s3")

# S3 Bucket Name
BUCKET_NAME = "your-bucket-name"

@app.get("/search-files/")
def search_files(
    start_date: str = Query(..., description="Start date in YYYY-MM-DD format"),
    end_date: str = Query(..., description="End date in YYYY-MM-DD format")
) -> List[dict]:
    """
    Search S3 files within the given date range.
    """
    try:
        # Convert string dates to datetime
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")

        # Get all objects in the bucket
        response = s3_client.list_objects_v2(Bucket=BUCKET_NAME)
        if "Contents" not in response:
            return []

        # Filter files by last modified date
        files = [
            {
                "key": obj["Key"],
                "last_modified": obj["LastModified"].strftime("%Y-%m-%d %H:%M:%S"),
                "size": obj["Size"]
            }
            for obj in response["Contents"]
            if start_dt <= obj["LastModified"].replace(tzinfo=None) <= end_dt
        ]

        return files

    except Exception as e:
        return {"error": str(e)}

# To run: uvicorn filename:app --reload

How It Works

    The API exposes an endpoint /search-files/
    The user provides start_date and end_date as query parameters
    The script lists all files in the S3 bucket and filters them by the LastModified date

Example Usage
Request:

GET http://127.0.0.1:8000/search-files/?start_date=2024-01-01&end_date=2024-02-01

Response:

[
    {
        "key": "folder/file1.txt",
        "last_modified": "2024-01-15 10:30:00",
        "size": 1024
    },
    {
        "key": "folder/file2.csv",
        "last_modified": "2024-01-25 14:20:30",
        "size": 2048
    }
]

Would you like to extend this with additional filters or authentication? ðŸš€
You said:
using lamdba python api
ChatGPT said:

To create an AWS Lambda function that exposes S3 files for searching based on date criteria, you can use AWS API Gateway as the HTTP interface and Boto3 to interact with S3.
Solution Overview

    AWS Lambda - Runs the API logic and filters files by date.
    API Gateway - Exposes a RESTful API endpoint for users to interact with the Lambda function.
    Boto3 - Retrieves file details from S3.
    IAM Role - Grants Lambda permission to read from S3.

Lambda Function Code

Create a Python file (lambda_function.py) for your AWS Lambda function.

import json
import boto3
from datetime import datetime
from urllib.parse import parse_qs

# Initialize S3 Client
s3_client = boto3.client("s3")

# S3 Bucket Name
BUCKET_NAME = "your-bucket-name"

def lambda_handler(event, context):
    """
    AWS Lambda function to search S3 files based on date criteria.
    """
    try:
        # Parse query parameters from API Gateway request
        params = parse_qs(event.get("queryStringParameters", {}) or {})
        start_date = params.get("start_date", [None])[0]
        end_date = params.get("end_date", [None])[0]

        if not start_date or not end_date:
            return {
                "statusCode": 400,
                "body": json.dumps({"error": "Both start_date and end_date are required (format: YYYY-MM-DD)"})
            }

        # Convert string dates to datetime
        start_dt = datetime.strptime(start_date, "%Y-%m-%d")
        end_dt = datetime.strptime(end_date, "%Y-%m-%d")

        # List all objects in the S3 bucket
        response = s3_client.list_objects_v2(Bucket=BUCKET_NAME)
        if "Contents" not in response:
            return {"statusCode": 200, "body": json.dumps([])}

        # Filter files by last modified date
        files = [
            {
                "key": obj["Key"],
                "last_modified": obj["LastModified"].strftime("%Y-%m-%d %H:%M:%S"),
                "size": obj["Size"]
            }
            for obj in response["Contents"]
            if start_dt <= obj["LastModified"].replace(tzinfo=None) <= end_dt
        ]

        return {
            "statusCode": 200,
            "body": json.dumps(files)
        }

    except Exception as e:
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }

Deploying to AWS Lambda
Step 1: Create an IAM Role for Lambda

    Go to AWS IAM Console â†’ Roles
    Click Create Role â†’ AWS Service â†’ Lambda
    Attach the AmazonS3ReadOnlyAccess policy
    Create the role and note its ARN

Step 2: Deploy Lambda Function

    Open AWS Lambda Console
    Click Create Function â†’ Author from scratch
    Set:
        Name: s3_search_lambda
        Runtime: Python 3.11
        Role: Select the IAM role created earlier
    Click Create Function
    In Function Code, upload your lambda_function.py or paste the code
    Click Deploy

Step 3: Set Up API Gateway

    Open API Gateway Console
    Click Create API â†’ HTTP API
    Click Add Integration â†’ Select Lambda Function â†’ Choose s3_search_lambda
    Set Method: GET
    Deploy the API
    Note the Invoke URL (e.g., https://xyz123.execute-api.us-east-1.amazonaws.com)

Testing the API
Example Request

curl "https://xyz123.execute-api.us-east-1.amazonaws.com/search-files?start_date=2024-01-01&end_date=2024-02-01"

Example Response

[
    {
        "key": "folder/file1.txt",
        "last_modified": "2024-01-15 10:30:00",
        "size": 1024
    },
    {
        "key": "folder/file2.csv",
        "last_modified": "2024-01-25 14:20:30",
        "size": 2048
    }
]

Next Steps

    âœ… Enable CORS in API Gateway if needed
    âœ… Optimize for large buckets by using pagination (ContinuationToken)
    âœ… Add authentication using IAM Roles or API Keys

Would you like to extend it with file content search or pagination? ðŸš€


